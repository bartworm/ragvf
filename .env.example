# ==================== API KEYS ====================
# OpenAI API Key (opcional - funciona en modo Mock sin esto)
OPENAI_API_KEY=sk-your-openai-api-key-here

# Anthropic API Key (opcional)
ANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here

GOOGLE_API_KEY=your-google-api-key-here

# Groq API Key (opcional - FREE, 14,400 requests/día)
# Obtén tu key en: https://console.groq.com
GROQ_API_KEY=your-groq-api-key-here

# ==================== RUTAS ====================
# Directorio con PDFs a procesar
PDF_DIR=data/pdfs

# Directorio para base de datos Qdrant
QDRANT_DIR=data/qdrant

# Directorio para almacenamiento Parquet
PARQUET_DIR=data/parquet


# ==================== EXTRACCIÓN ====================
# Nivel de extracción (0-4)
# 0: Texto plano
# 1: + Bibliografía
# 2: + Layout (columnas)
# 3: + Tablas
# 4: + Contexto de tablas
EXTRACTION_LEVEL=3

# Tamaño de chunks de texto (caracteres)
CHUNK_SIZE=1000

# Solapamiento entre chunks
CHUNK_OVERLAP=150


# ==================== RETRIEVAL ====================
# Número de resultados iniciales antes de reranking
K_RETRIEVAL=20

# Número de resultados finales después de reranking
K_FINAL=10


# ==================== LLM ====================
# Proveedor de LLM (openai, google, groq, ollama, mock)
LLM_PROVIDER=ollama

# Modelo a usar (depende del proveedor)
# Ollama: llama3.2-vision, llama3.1:8b, llama3.3
# OpenAI: gpt-3.5-turbo, gpt-4, gpt-4-turbo
# Google: gemini-1.5-flash, gemini-2.0-flash-exp
# Groq: llama-3.3-70b-versatile, mixtral-8x7b-32768
LLM_MODEL=llama3.2-vision

# Temperatura del modelo (0.0-1.0)
# 0.0 = más conservador, 1.0 = más creativo
LLM_TEMPERATURE=0.3


# ==================== DEBUG ====================
# Modo debug (true/false)
DEBUG=false
