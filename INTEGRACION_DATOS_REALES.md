# üîß Gu√≠a: Integraci√≥n de Datos Reales en el Benchmark

## ‚ö†Ô∏è Estado Actual

El benchmark actual (`benchmark.py`) usa **MockRetriever** que genera datos simulados. Para usar **datos reales de tus PDFs**, necesitas completar estos pasos:

---

## üìã Paso 1: Indexar tus PDFs

Antes de ejecutar el benchmark con datos reales, debes indexar tus PDFs en Qdrant y Parquet.

### Crear script de indexaci√≥n (`indexar_pdfs.py`):

```python
#!/usr/bin/env python3
"""
Script para indexar PDFs en Qdrant y Parquet.

Uso:
    python indexar_pdfs.py data/pdfs/
"""

import sys
from pathlib import Path
from sentence_transformers import SentenceTransformer

from config import RAGConfig
from rag.extraction.extractors import PDFContentExtractor
from rag.extraction.table_representations import TableRepresentationGenerator
from rag.storage.qdrant_store import QdrantVectorStore
from rag.storage.persistence import ParquetPersistence

def main():
    # Cargar config
    config = RAGConfig.from_env()

    # Inicializar componentes
    print("üîß Inicializando componentes...")

    # 1. Extractor de PDFs
    extractor = PDFContentExtractor()
    table_gen = TableRepresentationGenerator()

    # 2. Modelo de embeddings
    embedding_model = SentenceTransformer(config.EMBEDDING_MODEL)

    def embed_func(text):
        return embedding_model.encode(text).tolist()

    # 3. Qdrant
    qdrant = QdrantVectorStore(
        path=config.QDRANT_DIR,
        embedding_dim=config.VECTOR_SIZE
    )
    qdrant.setup_collections()

    # 4. Parquet
    parquet = ParquetPersistence(config.PARQUET_DIR)

    # Procesar cada PDF
    pdf_dir = Path("data/pdfs")
    pdfs = list(pdf_dir.glob("*.pdf"))

    print(f"\nüìÑ Procesando {len(pdfs)} PDFs...")

    for i, pdf_file in enumerate(pdfs, 1):
        print(f"\n[{i}/{len(pdfs)}] {pdf_file.name}")

        try:
            # Extraer contenido
            text_chunks, tables = extractor.extract_from_pdf(pdf_file)

            # Generar representaciones de tablas
            descriptors = []
            summaries = []

            for table in tables:
                desc = table_gen.create_descriptor(table)
                summ = table_gen.create_summary(table)
                descriptors.append(desc)
                summaries.append(summ)

            # Indexar en Qdrant
            for chunk in text_chunks:
                embedding = embed_func(chunk.content)
                qdrant.index_text_chunk(chunk, embedding)

            for desc in descriptors:
                embedding = embed_func(desc.description)
                qdrant.index_table_descriptor(desc, embedding)

            for summ in summaries:
                embedding = embed_func(summ.summary_text)
                qdrant.index_table_summary(summ, embedding)

            # Guardar tablas completas en Parquet
            for table in tables:
                parquet.save_table(table)

            print(f"  ‚úÖ {len(text_chunks)} chunks, {len(tables)} tablas")

        except Exception as e:
            print(f"  ‚ùå Error: {e}")
            continue

    print("\n‚úÖ Indexaci√≥n completada!")
    print(f"   üìä Qdrant: {config.QDRANT_DIR}")
    print(f"   üíæ Parquet: {config.PARQUET_DIR}")


if __name__ == "__main__":
    main()
```

### Ejecutar indexaci√≥n:

```bash
python indexar_pdfs.py
```

---

## üìã Paso 2: Modificar benchmark.py

### 2.1 Ya est√°n los imports correctos (l√≠neas 40-48):

```python
from rag.retrieval.two_stage_retriever import TwoStageRetriever
from rag.retrieval.baseline_retriever import BaselineRetriever
from rag.storage.qdrant_store import QdrantVectorStore
from rag.storage.persistence import ParquetPersistence
from sentence_transformers import SentenceTransformer
```

### 2.2 Ya est√° `_init_shared_components()` (l√≠neas 123-173)

Esto carga:
- ‚úÖ Modelo de embeddings
- ‚úÖ Qdrant store
- ‚úÖ Parquet storage
- ‚úÖ LLM

### 2.3 A√±adir m√©todo `_create_retriever()`:

**Insertar despu√©s de la l√≠nea 173** (despu√©s de `_init_shared_components`):

```python
    def _create_retriever(self, config_name: str):
        """
        Crea retriever seg√∫n configuraci√≥n.

        Args:
            config_name: Nombre de la configuraci√≥n

        Returns:
            Retriever configurado
        """
        if "baseline" in config_name:
            # Config 1: Baseline con Chroma (si tienes un vectorstore de Chroma)
            # Nota: Necesitas cargar tu vectorstore de Chroma del Hito 1
            try:
                from langchain_community.vectorstores import Chroma
                from langchain_community.embeddings import HuggingFaceEmbeddings

                embeddings = HuggingFaceEmbeddings(model_name=self.config.EMBEDDING_MODEL)
                vectorstore = Chroma(
                    persist_directory=str(self.config.CHROMA_DIR),  # A√±adir a config.py
                    embedding_function=embeddings
                )
                return BaselineRetriever(vectorstore)
            except:
                # Si no tienes Chroma, usa TwoStageRetriever b√°sico
                return TwoStageRetriever(
                    qdrant_store=self.qdrant_store,
                    parquet_storage=self.parquet_storage,
                    embedding_function=self.embed_func,
                    k_light=10,
                    k_full_tables=0  # Sin tablas para baseline
                )

        else:
            # Configs 2-5: TwoStageRetriever con diferentes par√°metros
            if "tablas" in config_name:
                k_light = 15
                k_full = 2
                threshold = 0.70
            elif "two_stage" in config_name:
                k_light = 20
                k_full = 3
                threshold = 0.75
            elif "reranking" in config_name or "full" in config_name:
                k_light = 20
                k_full = 3
                threshold = 0.75
            else:
                k_light = 20
                k_full = 3
                threshold = 0.75

            return TwoStageRetriever(
                qdrant_store=self.qdrant_store,
                parquet_storage=self.parquet_storage,
                embedding_function=self.embed_func,
                full_table_threshold=threshold,
                k_light=k_light,
                k_full_tables=k_full
            )
```

### 2.4 Reemplazar `create_pipeline()` (l√≠neas 191-395):

**Eliminar TODO el c√≥digo desde l√≠nea 191 hasta l√≠nea 395 y reemplazar con:**

```python
    def create_pipeline(self, config_name: str) -> RAGPipeline:
        """
        Crea un pipeline seg√∫n la configuraci√≥n especificada usando DATOS REALES.

        Args:
            config_name: Nombre de la configuraci√≥n

        Returns:
            RAGPipeline configurado

        Raises:
            RuntimeError: Si no hay datos indexados
        """
        print(f"\nüîß Configurando: {config_name}")

        # Validar que tenemos datos reales
        if self.qdrant_store is None or self.parquet_storage is None:
            raise RuntimeError(
                "\n‚ùå No hay datos indexados. Antes de ejecutar el benchmark debes:\n"
                "   1. Indexar PDFs: python indexar_pdfs.py\n"
                "   2. Verificar que existen:\n"
                f"      - {self.config.QDRANT_DIR}/\n"
                f"      - {self.config.PARQUET_DIR}/\n"
            )

        # Crear retriever REAL
        retriever = self._create_retriever(config_name)

        # Configurar componentes seg√∫n config
        if config_name == "1_baseline":
            # Config 1: Sin mejoras (baseline)
            pipeline = RAGPipeline(
                retriever=retriever,
                llm=self.llm,
                preprocessor=None,
                reranker=None,
                use_preprocessing=False,
                use_reranking=False,
                k_retrieval=10,
                k_final=5
            )

        elif config_name == "2_tablas":
            # Config 2: + Extracci√≥n de tablas
            pipeline = RAGPipeline(
                retriever=retriever,
                llm=self.llm,
                preprocessor=None,
                reranker=None,
                use_preprocessing=False,
                use_reranking=False,
                k_retrieval=15,
                k_final=7
            )

        elif config_name == "3_two_stage":
            # Config 3: + Retrieval en dos etapas
            pipeline = RAGPipeline(
                retriever=retriever,
                llm=self.llm,
                preprocessor=None,
                reranker=None,
                use_preprocessing=False,
                use_reranking=False,
                k_retrieval=20,
                k_final=8
            )

        elif config_name == "4_reranking":
            # Config 4: + Reranking
            reranker = Reranker()
            pipeline = RAGPipeline(
                retriever=retriever,
                llm=self.llm,
                preprocessor=None,
                reranker=reranker,
                use_preprocessing=False,
                use_reranking=True,
                k_retrieval=20,
                k_final=10
            )

        else:  # "5_full"
            # Config 5: + Preprocesamiento
            preprocessor = QueryPreprocessor(use_llm=False)
            reranker = Reranker()
            pipeline = RAGPipeline(
                retriever=retriever,
                llm=self.llm,
                preprocessor=preprocessor,
                reranker=reranker,
                use_preprocessing=True,
                use_reranking=True,
                k_retrieval=20,
                k_final=10
            )

        print(f"   ‚úÖ Pipeline creado (datos REALES)")
        return pipeline
```

---

## üìã Paso 3: Verificar

### 3.1 Verificar que hay datos indexados:

```bash
ls -la data/qdrant/
ls -la data/parquet/
```

Deber√≠as ver archivos de base de datos de Qdrant y archivos .parquet.

### 3.2 Ejecutar benchmark:

```bash
python benchmark.py --questions 5
```

Si no hay datos, ver√°s:
```
‚ùå No hay datos indexados. Antes de ejecutar el benchmark debes:
   1. Indexar PDFs: python indexar_pdfs.py
   ...
```

Si hay datos, ver√°s:
```
üî¨ BENCHMARK INCREMENTAL DEL RAG PIPELINE
================================================================================
üìù Preguntas cargadas: 5
...
```

---

## üéØ Resumen

### Antes de poder ejecutar el benchmark con datos reales necesitas:

1. ‚úÖ **Tener PDFs** en `data/pdfs/`
2. ‚úÖ **Ejecutar indexaci√≥n**: `python indexar_pdfs.py`
3. ‚úÖ **Modificar benchmark.py** seg√∫n esta gu√≠a
4. ‚úÖ **Ejecutar benchmark**: `python benchmark.py`

### El benchmark ahora:
- ‚ùå **NO acepta** datos simulados/mock
- ‚úÖ **REQUIERE** datos reales indexados
- ‚úÖ **Verifica** que existan Qdrant y Parquet
- ‚úÖ **Falla r√°pido** con mensaje claro si faltan datos

---

## üí° Alternativa m√°s r√°pida

Si quieres probar el benchmark SIN modificar c√≥digo, puedes:

1. Usar el `benchmark.py` actual (con Mocks) para **testing de la estructura**
2. Cuando tengas PDFs indexados, hacer los cambios de esta gu√≠a
3. Ejecutar el benchmark final con datos reales

---

¬øNecesitas ayuda con alg√∫n paso espec√≠fico?
